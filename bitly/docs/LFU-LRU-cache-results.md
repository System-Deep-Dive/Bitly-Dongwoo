## 캐시 정책(LRU vs. LFU) 성능 비교 테스트 케이스 및 결과 요약

이 문서는 Skewed(핫스팟 데이터) 워크로드 환경에서 레디스 캐시의 **LRU(Least Recently Used)**와 **LFU(Least Frequently Used)** 정책 간 성능을 비교 분석하기 위해 수행된 테스트의 상세 결과입니다.

### 🟢 가설

> "인기 있는 URL이 반복적으로 요청되는 상황(Skewed)에서는, 접근 빈도를 기반으로 데이터를 관리하는 **LFU**가 단순히 최근 사용 여부를 따지는 **LRU**보다 캐시 히트율이 높아 **더 우수한 성능**을 보일 것이다."

### 🟢 테스트 환경 및 설정

| 항목 | 내용 |
| :--- | :--- |
| **테스트 목표** | 동일한 Skewed 워크로드 하에서 LRU와 LFU 정책의 응답 시간, 성공률을 비교하여 가설 검증 |
| **테스트 도구** | k6 (ramping-arrival-rate executor 사용) |
| **테스트 대상** | Redis Cache를 사용하는 URL 리다이렉션 애플리케이션 |
| **테스트 데이터** | 500만 건의 URL |
| **핵심 변수** | **Redis `maxmemory-policy` 설정 (`allkeys-lru` vs `allkeys-lfu`)** |
| **테스트 부하** | 시나리오 1: 5,000 TPS (정상 부하) <br> 시나리오 2: 7,000 TPS (과부하) |
| **테스트 기간** | 각 시나리오별 5분 |

-----

### 🟢 실제 테스트 결과 및 분석

#### **시나리오 1: 정상 부하 (5,000 TPS) - 가설 검증 (PASS)**

이 시나리오에서는 LFU가 LRU 대비 모든 지표에서 월등한 성능을 보이며 **가설을 성공적으로 입증했습니다.**

- [LRU 정책 상세 테스트 결과](./cache/LRU-cache-5000-results.md)
- [LFU 정책 상세 테스트 결과](./cache/LFU-cache-5000-results.md)

| 지표 | `allkeys-lru` (LRU) | `allkeys-lfu` (LFU) | 결과 분석 |
| :--- | :--- | :--- | :--- |
| **성공률 (Success Rate)** | 98.37% | **99.96%** | LFU가 더 안정적으로 요청을 처리했습니다. |
| **p95 응답 시간** | 61.89ms | **4.3ms** | **LFU가 14배 이상 빠른 응답 속도**를 기록했습니다. |
| **평균 응답 시간** | 13ms | **2.25ms** | 평균 응답 시간 역시 LFU가 압도적으로 우수했습니다. |

**분석:** LFU 정책은 접근 빈도가 높은 '핫스팟 데이터'를 캐시에 효과적으로 유지하여 캐시 히트율을 극대화했습니다. 반면, LRU는 상대적으로 인기가 없지만 최근에 접근된 데이터 때문에 '진짜 인기 있는' 데이터가 캐시에서 밀려나면서 캐시 미스가 더 자주 발생했고, 이는 응답 시간 저하로 이어졌습니다.

-----

#### **시나리오 2: 시스템 과부하 (7,000 TPS) - 병목 현상 분석 (FAIL)**

이 시나리오에서는 두 정책 모두 요청을 감당하지 못하고 시스템이 마비되는 현상을 보였습니다. **캐시 정책 간의 유의미한 성능 비교가 불가능한 결과**입니다.

- [LRU 정책 상세 테스트 결과](./cache/LRU-cache-7000-results.md)
- [LFU 정책 상세 테스트 결과](./cache/LFU-cache-7000-results.md)

| 지표 | `allkeys-lru` (LRU) | `allkeys-lfu` (LFU) | 결과 분석 |
| :--- | :--- | :--- | :--- |
| **성공률 (Success Rate)** | 24.07% | 16.34% | 두 정책 모두 **성능 목표 달성에 실패**했습니다. |
| **p95 응답 시간** | 3.57초 | 3.92초 | 응답 시간이 초 단위로 폭증하며 사용 불가능한 상태가 되었습니다. |
| **`dropped_iterations`** | 83만+ 건 | 108만+ 건 | 시스템이 처리 용량을 초과하여 대량의 요청을 누락시켰습니다. |

**분석:** 과도한 요청으로 인해 캐시가 처리할 수 있는 용량을 넘어서자, 대량의 캐시 미스가 발생했습니다. 이 요청들은 후방의 데이터베이스로 모두 전달되어 DB 병목 현상을 유발했고, 결국 시스템 전체가 마비되었습니다.

**Grafana 모니터링 결과**를 보면, 두 정책 모두에서 캐시 히트율이 급락하고 미스율이 치솟는 **거의 동일한 경향의 그래프**가 관측되었습니다. 이것이 '캐시 정책의 효율성' 문제가 아닌 '시스템의 절대적인 처리 용량 한계' 문제인 이유는 다음과 같습니다.

1.  **DB 병목 현상 발생:** 과도한 요청(7,000 iters/s)은 캐시가 감당하지 못하는 수의 캐시 미스(Cache Miss)를 유발합니다. 이 요청들이 모두 후방의 데이터베이스(DB)로 전달되면서 DB의 처리 용량을 초과하고, 응답 시간이 급격히 느려지는 병목 현상이 발생합니다.
2.  **애플리케이션 전체의 응답 지연:** DB 작업이 지연되면, DB의 응답을 기다리는 애플리케이션의 스레드(Thread)가 모두 고갈됩니다. 이로 인해 캐시에서 처리할 수 있었을 요청(Cache Hit)조차도 제때 처리되지 못하고 전체 시스템의 응답 속도가 초 단위로 급증합니다.
3.  **정책 무관한 시스템 마비:** 이 상태에 이르면 캐시 정책(LRU/LFU)의 효율성은 성능에 거의 영향을 주지 못합니다. DB와 애플리케이션이라는 후방 시스템이 마비되었기 때문에, 캐시가 아무리 효율적으로 동작하려 해도 소용이 없습니다. 두 정책에서 모두 응답 시간이 폭증하고 요청이 대량으로 누락(`dropped_iterations`)되는 동일한 실패 패턴이 나타나는 것이 바로 이 때문입니다.

결론적으로, 해당 테스트의 성능 저하는 캐시 정책의 우열이 아닌, **DB를 포함한 시스템 전체의 처리 용량(Throughput) 한계**에 도달했기 때문이라고 명확히 판단할 수 있습니다.

-----

### 최종 결론

1.  **가설 검증 성공:** 정상 부하(5,000 iters/s) 환경에서 **LFU는 LRU보다 월등히 높은 캐시 히트율과 빠른 응답 속도를 보여주며**, Skewed 워크로드에 더 적합한 정책임을 입증했습니다.

2.  **시스템 한계점 확인:** 과부하(7,000 iters/s) 테스트는 캐시 정책의 우열을 가리기보다, 현재 아키텍처가 **약 5,000 ~ 7,000 TPS 사이에서 병목 현상**이 발생하는 한계점을 가지고 있음을 확인시켜 주었습니다. 이 구간의 결과는 캐시 정책 비교 데이터로 사용하기에 부적합합니다.에 부적합합니다.